{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: Forward propagation**\n",
    "\n",
    "$$Z^{[1]} = W^{[1]} X + b^{[1]}$$\n",
    "$$A^{[1]} = g_{\\text{ReLU}}(Z^{[1]}))$$\n",
    "$$Z^{[2]} = W^{[2]} A^{[1]} + b^{[2]}$$\n",
    "$$A^{[2]} = g_{\\text{ReLU}}(Z^{[2]}))$$\n",
    "$$Z^{[3]} = W^{[3]} A^{[2]} + b^{[3]}$$\n",
    "$$A^{[3]} = g_{\\text{softmax}}(Z^{[3]})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self,n_inputs,n_outputs):\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        self.weights = np.random.rand(n_inputs,n_outputs)\n",
    "        self.biases = np.zeros((1,n_outputs))\n",
    "    def forward(self,X):\n",
    "        self.X = X\n",
    "        self.Z = self.X.dot(self.weights) + self.biases\n",
    "        return self.Z\n",
    "    def backward(self,Layer):\n",
    "        dz_dw = self.X\n",
    "        dz_db = np.ones_like(Layer.dbackward)\n",
    "        dz_dA = self.weights\n",
    "        self.dweights = dz_dw.T.dot(Layer.dbackward)\n",
    "        self.dbiases = np.sum(Layer.dbackward,axis=0,keepdims=True)\n",
    "        self.dbackward =Layer.dbackward.dot(dz_dA.T)\n",
    "class ReLU:\n",
    "    def forward(self,X):\n",
    "        self.A = np.maximum(0,X)\n",
    "        return self.A\n",
    "        \n",
    "    def backward(self,Layer):\n",
    "        dA_dz = np.where(Layer.dbackward>0,1,0)\n",
    "        self.dbackward = np.multiply(Layer.dbackward,dA_dz)\n",
    "    \n",
    "class SoftMax:\n",
    "    def __init__(self,n_inputs,n_outputs):\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "    def forward(self,X):\n",
    "        X = np.exp(X) / np.sum(np.exp(X),axis=1,keepdims=True)\n",
    "        return X\n",
    "\n",
    "class MSELoss:\n",
    "    def forward(self,Y_pred,Y_true):\n",
    "        self.Y_pred = Y_pred\n",
    "        self.Y_true = Y_true\n",
    "        self.loss = ((Y_pred-Y_true)**2).mean()\n",
    "        return self.loss\n",
    "    def backward(self):\n",
    "        self.dbackward = 2* (self.Y_pred - self.Y_true)\n",
    "        \n",
    "\n",
    "\n",
    "class OptimizerSGD:\n",
    "    def __init__(self,lr=0.1):\n",
    "        self.lr = lr\n",
    "    def update_params(self,Layer):\n",
    "        Layer.weights -= self.lr * Layer.dweights\n",
    "        Layer.biases -= self.lr * Layer.dbiases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self,n_inputs,n_outputs):\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        self.linear1 = Linear(n_inputs=self.n_inputs,n_outputs=64)\n",
    "        self.relu1 = ReLU()\n",
    "        self.linear2 = Linear(n_inputs=64,n_outputs=128)\n",
    "        self.relu2 = ReLU()\n",
    "        self.linear3 = Linear(n_inputs=128,n_outputs=self.n_outputs)\n",
    "        self.loss = MSELoss()\n",
    "    def forward(self,X):\n",
    "        X = self.linear1.forward(X)\n",
    "        X = self.relu1.forward(X)\n",
    "        X = self.linear2.forward(X)\n",
    "        X = self.relu2.forward(X)\n",
    "        X = self.linear3.forward(X)\n",
    "        return X\n",
    "    \n",
    "    def calculate_loss(self,y_pred,y_true):\n",
    "        self.loss.forward(y_pred,y_true)\n",
    "    def backward(self):\n",
    "        self.loss.backward()\n",
    "        self.linear3.backward(self.loss)\n",
    "        self.relu2.backward(self.linear3)\n",
    "        self.linear2.backward(self.relu2)\n",
    "        self.relu1.backward(self.linear2)\n",
    "        self.linear1.backward(self.relu1)\n",
    "    \n",
    "    def update(self):\n",
    "        optim = OptimizerSGD()\n",
    "        optim.update_params(self.linear1)\n",
    "        optim.update_params(self.linear2)\n",
    "        optim.update_params(self.linear3)\n",
    "    \n",
    "    def fit(self,X,y,epochs = 1000):\n",
    "        for i in range(epochs):\n",
    "            y_pred = self.forward(X)\n",
    "            self.calculate_loss(y_pred,y)\n",
    "            self.backward()\n",
    "            self.update()\n",
    "            print(y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,2,3,4,5,6]])\n",
    "y = np.array([[24,67,234,634]])\n",
    "model = NeuralNetwork(X.shape[1],y.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20616.85240773 20805.87032611 19019.1595783  22869.48062792]]\n",
      "[[-4118.57048155 -4147.77406522 -3757.03191566 -4447.09612558]]\n",
      "[[-3290.05638524 -3304.81925218 -2958.82553253 -3430.87690047]]\n",
      "[[-2627.24510819 -2630.45540174 -2320.26042602 -2617.90152037]]\n",
      "[[-2096.99608655 -2090.96432139 -1809.40834082 -1967.5212163 ]]\n",
      "[[-1672.79686924 -1659.37145711 -1400.72667265 -1447.21697304]]\n",
      "[[-1333.43749539 -1314.09716569 -1073.78133812 -1030.97357843]]\n",
      "[[-1061.94999631 -1037.87773255  -812.2250705   -697.97886275]]\n",
      "[[-844.75999705 -816.90218604 -602.9800564  -431.5830902 ]]\n",
      "[[-671.00799764 -640.12174883 -435.58404512 -218.46647216]]\n",
      "[[-532.00639811 -498.69739907 -301.6672361   -47.97317773]]\n",
      "[[-420.80511849 -385.55791925 -194.53378888   88.42145782]]\n",
      "[[-331.84409479 -295.0463354  -108.8270311   197.53716626]]\n",
      "[[-260.67527583 -222.63706832  -40.26162488  284.829733  ]]\n",
      "[[-203.74022067 -164.70965466   14.5907001   354.6637864 ]]\n",
      "[[-158.19217653 -118.36772373   58.47256008  410.53102912]]\n",
      "[[-121.75374123  -81.29417898   93.57804806  455.2248233 ]]\n",
      "[[-92.60299298 -51.63534318 121.66243845 490.97985864]]\n",
      "[[-69.28239439 -27.90827455 144.12995076 519.58388691]]\n",
      "[[-50.62591551  -8.92661964 162.10396061 542.46710953]]\n",
      "[[-35.70073241   6.25870429 176.48316849 560.77368762]]\n",
      "[[-23.76058593  18.40696343 187.98653479 575.4189501 ]]\n",
      "[[-14.20846874  28.12557075 197.18922783 587.13516008]]\n",
      "[[ -6.56677499  35.9004566  204.55138226 596.50812806]]\n",
      "[[-4.53419994e-01  4.21203653e+01  2.10441106e+02  6.04006502e+02]]\n",
      "[[  4.43726401  47.09629222 215.15288465 610.00520196]]\n",
      "[[  8.3498112   51.07703378 218.92230772 614.80416157]]\n",
      "[[ 11.47984896  54.26162702 221.93784618 618.64332925]]\n",
      "[[ 13.98387917  56.80930162 224.35027694 621.7146634 ]]\n",
      "[[ 15.98710334  58.84744129 226.28022155 624.17173072]]\n",
      "[[ 17.58968267  60.47795304 227.82417724 626.13738458]]\n",
      "[[ 18.87174614  61.78236243 229.05934179 627.70990766]]\n",
      "[[ 19.89739691  62.82588994 230.04747343 628.96792613]]\n",
      "[[ 20.71791753  63.66071195 230.83797875 629.9743409 ]]\n",
      "[[ 21.37433402  64.32856956 231.470383   630.77947272]]\n",
      "[[ 21.89946722  64.86285565 231.9763064  631.42357818]]\n",
      "[[ 22.31957377  65.29028452 232.38104512 631.93886254]]\n",
      "[[ 22.65565902  65.63222762 232.7048361  632.35109003]]\n",
      "[[ 22.92452722  65.90578209 232.96386888 632.68087203]]\n",
      "[[ 23.13962177  66.12462567 233.1710951  632.94469762]]\n",
      "[[ 23.31169742  66.29970054 233.33687608 633.1557581 ]]\n",
      "[[ 23.44935793  66.43976043 233.46950086 633.32460648]]\n",
      "[[ 23.55948635  66.55180835 233.57560069 633.45968518]]\n",
      "[[ 23.64758908  66.64144668 233.66048055 633.56774815]]\n",
      "[[ 23.71807126  66.71315734 233.72838444 633.65419852]]\n",
      "[[ 23.77445701  66.77052587 233.78270755 633.72335881]]\n",
      "[[ 23.81956561  66.8164207  233.82616604 633.77868705]]\n",
      "[[ 23.85565249  66.85313656 233.86093283 633.82294964]]\n",
      "[[ 23.88452199  66.88250925 233.88874627 633.85835971]]\n",
      "[[ 23.90761759  66.9060074  233.91099701 633.88668777]]\n",
      "[[ 23.92609407  66.92480592 233.92879761 633.90935022]]\n",
      "[[ 23.94087526  66.93984473 233.94303809 633.92748017]]\n",
      "[[ 23.95270021  66.95187579 233.95443047 633.94198414]]\n",
      "[[ 23.96216017  66.96150063 233.96354438 633.95358731]]\n",
      "[[ 23.96972813  66.9692005  233.9708355  633.96286985]]\n",
      "[[ 23.97578251  66.9753604  233.9766684  633.97029588]]\n",
      "[[ 23.980626    66.98028832 233.98133472 633.9762367 ]]\n",
      "[[ 23.9845008   66.98423066 233.98506778 633.98098936]]\n",
      "[[ 23.98760064  66.98738453 233.98805422 633.98479149]]\n",
      "[[ 23.99008051  66.98990762 233.99044338 633.98783319]]\n",
      "[[ 23.99206441  66.9919261  233.9923547  633.99026655]]\n",
      "[[ 23.99365153  66.99354088 233.99388376 633.99221324]]\n",
      "[[ 23.99492122  66.9948327  233.99510701 633.99377059]]\n",
      "[[ 23.99593698  66.99586616 233.99608561 633.99501648]]\n",
      "[[ 23.99674958  66.99669293 233.99686849 633.99601318]]\n",
      "[[ 23.99739967  66.99735434 233.99749479 633.99681054]]\n",
      "[[ 23.99791973  66.99788347 233.99799583 633.99744844]]\n",
      "[[ 23.99833579  66.99830678 233.99839666 633.99795875]]\n",
      "[[ 23.99866863  66.99864542 233.99871733 633.998367  ]]\n",
      "[[ 23.9989349   66.99891634 233.99897387 633.9986936 ]]\n",
      "[[ 23.99914792  66.99913307 233.99917909 633.99895488]]\n",
      "[[ 23.99931834  66.99930646 233.99934327 633.9991639 ]]\n",
      "[[ 23.99945467  66.99944517 233.99947462 633.99933112]]\n",
      "[[ 23.99956374  66.99955613 233.9995797  633.9994649 ]]\n",
      "[[ 23.99965099  66.99964491 233.99966376 633.99957192]]\n",
      "[[ 23.99972079  66.99971592 233.999731   633.99965753]]\n",
      "[[ 23.99977663  66.99977274 233.9997848  633.99972603]]\n",
      "[[ 23.99982131  66.99981819 233.99982784 633.99978082]]\n",
      "[[ 23.99985705  66.99985455 233.99986227 633.99982466]]\n",
      "[[ 23.99988564  66.99988364 233.99988982 633.99985973]]\n",
      "[[ 23.99990851  66.99990691 233.99991186 633.99988778]]\n",
      "[[ 23.99992681  66.99992553 233.99992948 633.99991022]]\n",
      "[[ 23.99994145  66.99994043 233.99994359 633.99992818]]\n",
      "[[ 23.99995316  66.99995234 233.99995487 633.99994254]]\n",
      "[[ 23.99996253  66.99996187 233.9999639  633.99995404]]\n",
      "[[ 23.99997002  66.9999695  233.99997112 633.99996323]]\n",
      "[[ 23.99997602  66.9999756  233.99997689 633.99997058]]\n",
      "[[ 23.99998081  66.99998048 233.99998151 633.99997647]]\n",
      "[[ 23.99998465  66.99998438 233.99998521 633.99998117]]\n",
      "[[ 23.99998772  66.99998751 233.99998817 633.99998494]]\n",
      "[[ 23.99999018  66.99999    233.99999054 633.99998795]]\n",
      "[[ 23.99999214  66.999992   233.99999243 633.99999036]]\n",
      "[[ 23.99999371  66.9999936  233.99999394 633.99999229]]\n",
      "[[ 23.99999497  66.99999488 233.99999515 633.99999383]]\n",
      "[[ 23.99999598  66.99999591 233.99999612 633.99999506]]\n",
      "[[ 23.99999678  66.99999672 233.9999969  633.99999605]]\n",
      "[[ 23.99999742  66.99999738 233.99999752 633.99999684]]\n",
      "[[ 23.99999794  66.9999979  233.99999802 633.99999747]]\n",
      "[[ 23.99999835  66.99999832 233.99999841 633.99999798]]\n",
      "[[ 23.99999868  66.99999866 233.99999873 633.99999838]]\n",
      "[[ 23.99999895  66.99999893 233.99999898 633.99999871]]\n",
      "[[ 23.99999916  66.99999914 233.99999919 633.99999896]]\n",
      "[[ 23.99999932  66.99999931 233.99999935 633.99999917]]\n",
      "[[ 23.99999946  66.99999945 233.99999948 633.99999934]]\n",
      "[[ 23.99999957  66.99999956 233.99999958 633.99999947]]\n",
      "[[ 23.99999965  66.99999965 233.99999967 633.99999958]]\n",
      "[[ 23.99999972  66.99999972 233.99999973 633.99999966]]\n",
      "[[ 23.99999978  66.99999977 233.99999979 633.99999973]]\n",
      "[[ 23.99999982  66.99999982 233.99999983 633.99999978]]\n",
      "[[ 23.99999986  66.99999986 233.99999986 633.99999983]]\n",
      "[[ 23.99999989  66.99999988 233.99999989 633.99999986]]\n",
      "[[ 23.99999991  66.99999991 233.99999991 633.99999989]]\n",
      "[[ 23.99999993  66.99999993 233.99999993 633.99999991]]\n",
      "[[ 23.99999994  66.99999994 233.99999994 633.99999993]]\n",
      "[[ 23.99999995  66.99999995 233.99999996 633.99999994]]\n",
      "[[ 23.99999996  66.99999996 233.99999996 633.99999995]]\n",
      "[[ 23.99999997  66.99999997 233.99999997 633.99999996]]\n",
      "[[ 23.99999998  66.99999998 233.99999998 633.99999997]]\n",
      "[[ 23.99999998  66.99999998 233.99999998 633.99999998]]\n",
      "[[ 23.99999998  66.99999998 233.99999999 633.99999998]]\n",
      "[[ 23.99999999  66.99999999 233.99999999 633.99999999]]\n",
      "[[ 23.99999999  66.99999999 233.99999999 633.99999999]]\n",
      "[[ 23.99999999  66.99999999 233.99999999 633.99999999]]\n",
      "[[ 23.99999999  66.99999999 233.99999999 633.99999999]]\n",
      "[[ 24.          66.99999999 234.         633.99999999]]\n",
      "[[ 24.  67. 234. 634.]]\n",
      "[[ 24.  67. 234. 634.]]\n",
      "[[ 24.  67. 234. 634.]]\n",
      "[[ 24.  67. 234. 634.]]\n",
      "[[ 24.  67. 234. 634.]]\n",
      "[[ 24.  67. 234. 634.]]\n",
      "[[ 24.  67. 234. 634.]]\n",
      "[[ 24.  67. 234. 634.]]\n",
      "[[ 24.  67. 234. 634.]]\n",
      "[[ 24.  67. 234. 634.]]\n",
      "[[ 24.  67. 234. 634.]]\n",
      "[[ 24.  67. 234. 634.]]\n",
      "[[ 24.  67. 234. 634.]]\n",
      "[[ 24.  67. 234. 634.]]\n",
      "[[ 24.  67. 234. 634.]]\n",
      "[[ 24.  67. 234. 634.]]\n",
      "[[ 24.  67. 234. 634.]]\n",
      "[[ 24.  67. 234. 634.]]\n",
      "[[ 24.  67. 234. 634.]]\n",
      "[[ 24.  67. 234. 634.]]\n",
      "[[ 24.  67. 234. 634.]]\n",
      "[[ 24.  67. 234. 634.]]\n",
      "[[ 24.  67. 234. 634.]]\n",
      "[[ 24.  67. 234. 634.]]\n",
      "[[ 24.  67. 234. 634.]]\n"
     ]
    }
   ],
   "source": [
    "model.fit(X,y,epochs=150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorchenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5581cd8f8e7f555d1c7b7d5c73b743c62e9c35962a29bf47b3ccdfb22fa58433"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
